{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Blackjack_mutiple_process.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mia1996/r-rlcard_test/blob/master/Blackjack_mutiple_process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A88uUTIFLlCX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "# <a href='https://github.com/datamllab/rlcard'> <center> <img src='https://miro.medium.com/max/1000/1*_9abDpNTM9Cbsd2HEXYm9Q.png' width=500 class='center' /></a> \n",
        "\n",
        "## **Running Multiple Processes on Blackjack**\n",
        "The environments can be run with multiple processes to accelerate the training. Below is an example to train DQN on Blackjack with multiple processes.The example is shown below:\n",
        "\n",
        "Note that we must use if `__name__ == '__main__' `for multiprocessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ8CiXAJjQGi",
        "colab_type": "code",
        "outputId": "14ecc649-375b-4cab-8c7a-a9a6a4f5aaf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "pip install rlcard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rlcard in /usr/local/lib/python3.6/dist-packages (0.2.4)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.6/dist-packages (from rlcard) (3.2.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from rlcard) (20.4)\n",
            "Requirement already satisfied: pillow>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from rlcard) (7.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from rlcard) (1.18.4)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from rlcard) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->rlcard) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_A_Br3Jj0xW",
        "colab_type": "code",
        "outputId": "2f70bb5d-3a5a-4ee6-d02b-7b44af68f919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "pip install rlcard[tensorflow]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rlcard[tensorflow] in /usr/local/lib/python3.6/dist-packages (0.2.4)\n",
            "Requirement already satisfied: pillow>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from rlcard[tensorflow]) (7.0.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from rlcard[tensorflow]) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from rlcard[tensorflow]) (1.18.4)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.6/dist-packages (from rlcard[tensorflow]) (3.2.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from rlcard[tensorflow]) (20.4)\n",
            "Requirement already satisfied: tensorflow<2.0,>=1.14; extra == \"tensorflow\" in /usr/local/lib/python3.6/dist-packages (from rlcard[tensorflow]) (1.15.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard[tensorflow]) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard[tensorflow]) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard[tensorflow]) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard[tensorflow]) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->rlcard[tensorflow]) (1.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (3.2.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (1.29.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (1.15.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (3.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (47.1.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2.0,>=1.14; extra == \"tensorflow\"->rlcard[tensorflow]) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6f7kJGML8Dk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "import rlcard\n",
        "from rlcard.agents import DQNAgent\n",
        "from rlcard.utils import set_global_seed, tournament\n",
        "from rlcard.utils import Logger"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDdHoimFMWUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    # Make environment\n",
        "    env = rlcard.make('blackjack', config={'seed': 0, 'env_num': 4})\n",
        "    eval_env = rlcard.make('blackjack', config={'seed': 0, 'env_num': 4})\n",
        "\n",
        "    # Set the iterations numbers and how frequently we evaluate performance\n",
        "    evaluate_every = 100\n",
        "    evaluate_num = 10000\n",
        "    iteration_num = 5000\n",
        "\n",
        "    # The intial memory size\n",
        "    memory_init_size = 100\n",
        "\n",
        "    # Train the agent every X steps\n",
        "    train_every = 1\n",
        "\n",
        "    # The paths for saving the logs and learning curves\n",
        "    log_dir = './experiments/blackjack_dqn_result/'\n",
        "\n",
        "    # Set a global seed\n",
        "    set_global_seed(0)\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "\n",
        "        # Initialize a global step\n",
        "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "\n",
        "        # Set up the agents\n",
        "        agent = DQNAgent(sess,\n",
        "                         scope='dqn',\n",
        "                         action_num=env.action_num,\n",
        "                         replay_memory_init_size=memory_init_size,\n",
        "                         train_every=train_every,\n",
        "                         state_shape=env.state_shape,\n",
        "                         mlp_layers=[10,10])\n",
        "        env.set_agents([agent])\n",
        "        eval_env.set_agents([agent])\n",
        "\n",
        "        # Initialize global variables\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        # Initialize a Logger to plot the learning curve\n",
        "        logger = Logger(log_dir)\n",
        "\n",
        "        for iteration in range(iteration_num):\n",
        "\n",
        "            # Generate data from the environment\n",
        "            trajectories, _ = env.run(is_training=True)\n",
        "\n",
        "            # Feed transitions into agent memory, and train the agent\n",
        "            for ts in trajectories[0]:\n",
        "                agent.feed(ts)\n",
        "\n",
        "            # Evaluate the performance. Play with random agents.\n",
        "            if iteration % evaluate_every == 0:\n",
        "                logger.log_performance(env.timestep, tournament(eval_env, evaluate_num)[0])\n",
        "        \n",
        "        # Save model\n",
        "        save_dir = 'models/blackjack_dqn'\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "        saver = tf.train.Saver()\n",
        "        saver.save(sess, os.path.join(save_dir, 'model'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EofrekuMdgn",
        "colab_type": "code",
        "outputId": "64b0c10e-39e0-4784-ad7e-463f05628164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/utils/utils.py:332: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:239: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:256: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:267: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/normalization.py:327: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:280: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:242: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:242: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:242: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:244: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:247: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_global_step\n",
            "\n",
            "----------------------------------------\n",
            "  timestep     |  4\n",
            "  reward       |  -0.7399\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 100, rl-loss: 1.0956813097000122WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:364: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 541, rl-loss: 0.6026347279548645\n",
            "----------------------------------------\n",
            "  timestep     |  541\n",
            "  reward       |  -0.066\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 1099, rl-loss: 0.6058878898620605\n",
            "----------------------------------------\n",
            "  timestep     |  1099\n",
            "  reward       |  -0.0691\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 1100, rl-loss: 0.4600841701030731\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 1627, rl-loss: 0.5869379043579102\n",
            "----------------------------------------\n",
            "  timestep     |  1627\n",
            "  reward       |  -0.0753\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 2100, rl-loss: 0.6174850463867188\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 2189, rl-loss: 0.5101578235626221\n",
            "----------------------------------------\n",
            "  timestep     |  2189\n",
            "  reward       |  -0.0694\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 2726, rl-loss: 0.43811458349227905\n",
            "----------------------------------------\n",
            "  timestep     |  2726\n",
            "  reward       |  -0.0556\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 3100, rl-loss: 0.7509120106697083\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 3280, rl-loss: 0.5478805303573608\n",
            "----------------------------------------\n",
            "  timestep     |  3280\n",
            "  reward       |  -0.0853\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 3839, rl-loss: 0.5439354777336121\n",
            "----------------------------------------\n",
            "  timestep     |  3839\n",
            "  reward       |  -0.0782\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 4100, rl-loss: 0.5503383278846741\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 4397, rl-loss: 0.779647707939148\n",
            "----------------------------------------\n",
            "  timestep     |  4397\n",
            "  reward       |  -0.0781\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 4950, rl-loss: 0.5241678953170776\n",
            "----------------------------------------\n",
            "  timestep     |  4950\n",
            "  reward       |  -0.0689\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 5100, rl-loss: 0.5438821911811829\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 5506, rl-loss: 0.5144636631011963\n",
            "----------------------------------------\n",
            "  timestep     |  5506\n",
            "  reward       |  -0.0684\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 6071, rl-loss: 0.4934130012989044\n",
            "----------------------------------------\n",
            "  timestep     |  6071\n",
            "  reward       |  -0.0633\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 6100, rl-loss: 0.42859354615211487\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 6644, rl-loss: 0.6766248345375061\n",
            "----------------------------------------\n",
            "  timestep     |  6644\n",
            "  reward       |  -0.0664\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 7100, rl-loss: 0.6252628564834595\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 7221, rl-loss: 0.8283538818359375\n",
            "----------------------------------------\n",
            "  timestep     |  7221\n",
            "  reward       |  -0.0758\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 7774, rl-loss: 0.46493014693260193\n",
            "----------------------------------------\n",
            "  timestep     |  7774\n",
            "  reward       |  -0.065\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 8100, rl-loss: 0.6778500080108643\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 8348, rl-loss: 0.5381323099136353\n",
            "----------------------------------------\n",
            "  timestep     |  8348\n",
            "  reward       |  -0.0696\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 8897, rl-loss: 0.6368733644485474\n",
            "----------------------------------------\n",
            "  timestep     |  8897\n",
            "  reward       |  -0.0702\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 9100, rl-loss: 0.5569663643836975\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 9467, rl-loss: 0.6883324980735779\n",
            "----------------------------------------\n",
            "  timestep     |  9467\n",
            "  reward       |  -0.0489\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 10033, rl-loss: 0.5263139009475708\n",
            "----------------------------------------\n",
            "  timestep     |  10033\n",
            "  reward       |  -0.0703\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 10100, rl-loss: 0.6863312721252441\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 10636, rl-loss: 0.4928438365459442\n",
            "----------------------------------------\n",
            "  timestep     |  10636\n",
            "  reward       |  -0.0602\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 11100, rl-loss: 0.5286944508552551\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 11218, rl-loss: 0.5120810270309448\n",
            "----------------------------------------\n",
            "  timestep     |  11218\n",
            "  reward       |  -0.0742\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 11796, rl-loss: 0.4883652329444885\n",
            "----------------------------------------\n",
            "  timestep     |  11796\n",
            "  reward       |  -0.0656\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 12100, rl-loss: 0.5364532470703125\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 12413, rl-loss: 0.5073115229606628\n",
            "----------------------------------------\n",
            "  timestep     |  12413\n",
            "  reward       |  -0.0717\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 13001, rl-loss: 0.7639986276626587\n",
            "----------------------------------------\n",
            "  timestep     |  13001\n",
            "  reward       |  -0.0728\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 13100, rl-loss: 0.6749976873397827\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 13584, rl-loss: 0.394100159406662\n",
            "----------------------------------------\n",
            "  timestep     |  13584\n",
            "  reward       |  -0.0566\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 14100, rl-loss: 0.41783714294433594\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 14163, rl-loss: 0.6457048058509827\n",
            "----------------------------------------\n",
            "  timestep     |  14163\n",
            "  reward       |  -0.0508\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 14772, rl-loss: 0.6962716579437256\n",
            "----------------------------------------\n",
            "  timestep     |  14772\n",
            "  reward       |  -0.0652\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 15100, rl-loss: 0.5519866943359375\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 15370, rl-loss: 0.48996108770370483\n",
            "----------------------------------------\n",
            "  timestep     |  15370\n",
            "  reward       |  -0.0803\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 15971, rl-loss: 0.6750391721725464\n",
            "----------------------------------------\n",
            "  timestep     |  15971\n",
            "  reward       |  -0.071\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 16100, rl-loss: 0.49468088150024414\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 16581, rl-loss: 0.5764397382736206\n",
            "----------------------------------------\n",
            "  timestep     |  16581\n",
            "  reward       |  -0.0683\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 17100, rl-loss: 0.4728034734725952\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 17179, rl-loss: 0.4820243716239929\n",
            "----------------------------------------\n",
            "  timestep     |  17179\n",
            "  reward       |  -0.0646\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 17788, rl-loss: 0.40933650732040405\n",
            "----------------------------------------\n",
            "  timestep     |  17788\n",
            "  reward       |  -0.0823\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 18100, rl-loss: 0.540005624294281\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 18408, rl-loss: 0.5852022171020508\n",
            "----------------------------------------\n",
            "  timestep     |  18408\n",
            "  reward       |  -0.0628\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 19022, rl-loss: 0.7219164967536926\n",
            "----------------------------------------\n",
            "  timestep     |  19022\n",
            "  reward       |  -0.0915\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 19100, rl-loss: 0.6447409391403198\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 19628, rl-loss: 0.4258766770362854\n",
            "----------------------------------------\n",
            "  timestep     |  19628\n",
            "  reward       |  -0.0732\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 20100, rl-loss: 0.6021704077720642\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 20228, rl-loss: 0.5215957164764404\n",
            "----------------------------------------\n",
            "  timestep     |  20228\n",
            "  reward       |  -0.0711\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 20851, rl-loss: 0.4154014587402344\n",
            "----------------------------------------\n",
            "  timestep     |  20851\n",
            "  reward       |  -0.0629\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 21100, rl-loss: 0.5164810419082642\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 21465, rl-loss: 0.4558759033679962\n",
            "----------------------------------------\n",
            "  timestep     |  21465\n",
            "  reward       |  -0.0687\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 22082, rl-loss: 0.5519828200340271\n",
            "----------------------------------------\n",
            "  timestep     |  22082\n",
            "  reward       |  -0.0629\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 22100, rl-loss: 0.5951641798019409\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 22692, rl-loss: 0.4516165256500244\n",
            "----------------------------------------\n",
            "  timestep     |  22692\n",
            "  reward       |  -0.0678\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 23100, rl-loss: 0.723185122013092\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 23317, rl-loss: 0.7588373422622681\n",
            "----------------------------------------\n",
            "  timestep     |  23317\n",
            "  reward       |  -0.0497\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 23963, rl-loss: 0.4788249433040619\n",
            "----------------------------------------\n",
            "  timestep     |  23963\n",
            "  reward       |  -0.0737\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 24100, rl-loss: 0.5787351131439209\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 24575, rl-loss: 0.6130774021148682\n",
            "----------------------------------------\n",
            "  timestep     |  24575\n",
            "  reward       |  -0.068\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 25100, rl-loss: 0.5046749114990234\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 25184, rl-loss: 0.6263934373855591\n",
            "----------------------------------------\n",
            "  timestep     |  25184\n",
            "  reward       |  -0.0686\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 25840, rl-loss: 0.5344563722610474\n",
            "----------------------------------------\n",
            "  timestep     |  25840\n",
            "  reward       |  -0.0743\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 26100, rl-loss: 0.7072450518608093\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 26456, rl-loss: 0.480413019657135\n",
            "----------------------------------------\n",
            "  timestep     |  26456\n",
            "  reward       |  -0.0655\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 27092, rl-loss: 0.6483006477355957\n",
            "----------------------------------------\n",
            "  timestep     |  27092\n",
            "  reward       |  -0.0747\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 27100, rl-loss: 0.5688895583152771\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 27731, rl-loss: 0.5380850434303284\n",
            "----------------------------------------\n",
            "  timestep     |  27731\n",
            "  reward       |  -0.0533\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 28100, rl-loss: 0.48328897356987\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 28350, rl-loss: 0.6657267808914185\n",
            "----------------------------------------\n",
            "  timestep     |  28350\n",
            "  reward       |  -0.0903\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 28965, rl-loss: 0.5914641618728638\n",
            "----------------------------------------\n",
            "  timestep     |  28965\n",
            "  reward       |  -0.0677\n",
            "----------------------------------------\n",
            "INFO - Agent dqn, step 29100, rl-loss: 0.5041288137435913\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Agent dqn, step 29584, rl-loss: 0.4957030117511749./experiments/blackjack_dqn_result/performance.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
