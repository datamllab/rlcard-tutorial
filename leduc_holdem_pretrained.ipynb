{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "leduc_holdem_pretrained.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mia1996/rlcard-tutoirial/blob/master/leduc_holdem_pretrained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miBl4S8JARzX"
      },
      "source": [
        "\n",
        "\n",
        "# <a href='https://github.com/datamllab/rlcard'> <center> <img src='https://miro.medium.com/max/1000/1*_9abDpNTM9Cbsd2HEXYm9Q.png' width=500 class='center' /></a> \n",
        "\n",
        "## **Having Fun with Pretrained Leduc Model**\n",
        "We have designed simple human interfaces to play against the pre-trained model of Leduc Hold'em. We will go through this process to have fun!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8USmiveSRO5"
      },
      "source": [
        "First, we install RLCard and PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ8CiXAJjQGi",
        "outputId": "a0b7fab7-bb43-4d97-9a36-5bbb89b164a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install rlcard[torch]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rlcard[torch]\n",
            "  Downloading rlcard-1.0.7.tar.gz (268 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 26.9 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 16.5 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 1.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 1.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61 kB 1.5 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71 kB 1.5 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81 kB 1.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92 kB 1.9 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 133 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 153 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 163 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 174 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 184 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 194 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 204 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 215 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 225 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 245 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 256 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 266 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 268 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.7/dist-packages (from rlcard[torch]) (1.21.5)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from rlcard[torch]) (1.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from rlcard[torch]) (1.10.0+cu111)\n",
            "Collecting GitPython\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 65.3 MB/s \n",
            "\u001b[?25hCollecting gitdb2\n",
            "  Downloading gitdb2-4.0.2-py3-none-any.whl (1.1 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from rlcard[torch]) (3.2.2)\n",
            "Collecting gitdb>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 786 kB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython->rlcard[torch]) (3.10.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->rlcard[torch]) (1.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->rlcard[torch]) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->rlcard[torch]) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->rlcard[torch]) (3.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->rlcard[torch]) (1.15.0)\n",
            "Building wheels for collected packages: rlcard\n",
            "  Building wheel for rlcard (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rlcard: filename=rlcard-1.0.7-py3-none-any.whl size=325373 sha256=56a06885c7d49be2ca8e7f3b52863880542503cae61a78df1bb3d75e929442a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/90/bd/bc402a48ca90970c9a7c2c4387dcb885fdf6073ec231a605ad\n",
            "Successfully built rlcard\n",
            "Installing collected packages: smmap, gitdb, rlcard, GitPython, gitdb2\n",
            "Successfully installed GitPython-3.1.27 gitdb-4.0.9 gitdb2-4.0.2 rlcard-1.0.7 smmap-5.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we load rlcard, model zoos in rlcard, and the human agent."
      ],
      "metadata": {
        "id": "sJOXjmEp_TTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import rlcard\n",
        "from rlcard import models\n",
        "from rlcard.agents import LeducholdemHumanAgent as HumanAgent\n",
        "from rlcard.utils import print_card"
      ],
      "metadata": {
        "id": "hgD5JUeM_h3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create the environment and make the opponent the pre-trained model."
      ],
      "metadata": {
        "id": "1GmR_nGC_hNl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_A_Br3Jj0xW"
      },
      "source": [
        "env = rlcard.make('leduc-holdem')\n",
        "human_agent = HumanAgent(env.num_actions)\n",
        "cfr_agent = models.load('leduc-holdem-cfr').agents[0]\n",
        "env.set_agents([\n",
        "    human_agent,\n",
        "    cfr_agent,\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEg4DyV0TPmN"
      },
      "source": [
        "We can start now!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_8Kuf47kghG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec4ce81-f813-4def-89cd-644a8f5e4243"
      },
      "source": [
        "print(\">> Leduc Hold'em pre-trained model\")\n",
        "\n",
        "while (True):\n",
        "    print(\">> Start a new game\")\n",
        "\n",
        "    trajectories, payoffs = env.run(is_training=False)\n",
        "    # If the human does not take the final action, we need to\n",
        "    # print other players action\n",
        "    final_state = trajectories[0][-1]\n",
        "    action_record = final_state['action_record']\n",
        "    state = final_state['raw_obs']\n",
        "    _action_list = []\n",
        "    for i in range(1, len(action_record)+1):\n",
        "        if action_record[-i][0] == state['current_player']:\n",
        "            break\n",
        "        _action_list.insert(0, action_record[-i])\n",
        "    for pair in _action_list:\n",
        "        print('>> Player', pair[0], 'chooses', pair[1])\n",
        "\n",
        "    # Let's take a look at what the agent card is\n",
        "    print('===============     CFR Agent    ===============')\n",
        "    print_card(env.get_perfect_information()['hand_cards'][1])\n",
        "\n",
        "    print('===============     Result     ===============')\n",
        "    if payoffs[0] > 0:\n",
        "        print('You win {} chips!'.format(payoffs[0]))\n",
        "    elif payoffs[0] == 0:\n",
        "        print('It is a tie.')\n",
        "    else:\n",
        "        print('You lose {} chips!'.format(-payoffs[0]))\n",
        "    print('')\n",
        "\n",
        "    inputs = input(\"Press any key to continue, Q to exit\\n\")\n",
        "    if inputs.lower() == \"q\":\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Leduc Hold'em pre-trained model\n",
            ">> Start a new game\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   +\n",
            "Agent 1: ++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 1 chooses check\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++\n",
            "Agent 1: ++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++\n",
            "Agent 1: ++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            "===============     CFR Agent    ===============\n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "===============     Result     ===============\n",
            "You lose 5.0 chips!\n",
            "\n",
            "Press any key to continue, Q to exit\n",
            "Q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sad... we loose... (Open in Colab to see more)"
      ],
      "metadata": {
        "id": "h7ckmk5BAASI"
      }
    }
  ]
}