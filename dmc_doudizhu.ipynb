{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of blackjack_dqn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mia1996/rlcard-tutoirial/blob/master/dmc_doudizhu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miBl4S8JARzX"
      },
      "source": [
        "\n",
        "\n",
        "# <a href='https://github.com/datamllab/rlcard'> <center> <img src='https://miro.medium.com/max/1000/1*_9abDpNTM9Cbsd2HEXYm9Q.png' width=500 class='center' /></a> \n",
        "\n",
        "## **Deep Monte-Carlo on DouDizhu**\n",
        "Now let's try some large-scale games. We will train DMC agent developed in [DouZero](https://github.com/kwai/DouZero) to train strong agents on Dou Dizhu. We first install rlcard and PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ8CiXAJjQGi",
        "outputId": "011a1e5d-d1a3-44cb-c987-64f709b4d3f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install rlcard[torch]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rlcard[torch]\n",
            "  Downloading rlcard-1.0.7.tar.gz (268 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 268 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.7/dist-packages (from rlcard[torch]) (1.21.5)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from rlcard[torch]) (1.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from rlcard[torch]) (1.10.0+cu111)\n",
            "Collecting GitPython\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 38.2 MB/s \n",
            "\u001b[?25hCollecting gitdb2\n",
            "  Downloading gitdb2-4.0.2-py3-none-any.whl (1.1 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from rlcard[torch]) (3.2.2)\n",
            "Collecting gitdb>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 577 kB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython->rlcard[torch]) (3.10.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->rlcard[torch]) (1.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->rlcard[torch]) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->rlcard[torch]) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->rlcard[torch]) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->rlcard[torch]) (1.15.0)\n",
            "Building wheels for collected packages: rlcard\n",
            "  Building wheel for rlcard (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rlcard: filename=rlcard-1.0.7-py3-none-any.whl size=325373 sha256=6a7c5207b3ee173eb2719d488058723f29aed159377030c6bfd098a5cf603789\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/90/bd/bc402a48ca90970c9a7c2c4387dcb885fdf6073ec231a605ad\n",
            "Successfully built rlcard\n",
            "Installing collected packages: smmap, gitdb, rlcard, GitPython, gitdb2\n",
            "Successfully installed GitPython-3.1.27 gitdb-4.0.9 gitdb2-4.0.2 rlcard-1.0.7 smmap-5.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We import RLCard and DMC trainer."
      ],
      "metadata": {
        "id": "2bt-JVoXyTwM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_A_Br3Jj0xW"
      },
      "source": [
        "import rlcard\n",
        "from rlcard.agents.dmc_agent import DMCTrainer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2ltkfinYmiU"
      },
      "source": [
        "Let's create the Dou Dizhu environment and and take a look at it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_8Kuf47kghG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb85d944-d4f4-4d04-c099-39e574c86abc"
      },
      "source": [
        "env = rlcard.make(\"doudizhu\")\n",
        "print(\"Number of actions:\", env.num_actions)\n",
        "print(\"Number of players:\", env.num_players)\n",
        "print(\"Shape of state:\", env.state_shape)\n",
        "print(\"Shape of action:\", env.action_shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of actions: 27472\n",
            "Number of players: 3\n",
            "Shape of state: [[790], [901], [901]]\n",
            "Shape of action: [[54], [54], [54]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks really difficult. Let's solve it with DMC. This will run five processes to train on CPU. It will take a lot of time (hours to days). So we will not pause it in the tutorial."
      ],
      "metadata": {
        "id": "W2vJYyyqzVj3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bqfMncnJTYU",
        "outputId": "a7a3f51c-a1dc-46b7-b3b1-f4638e2400eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Initialize the DMC trainer\n",
        "trainer = DMCTrainer(\n",
        "    env,\n",
        "    cuda=\"\",\n",
        "    xpid=\"doudizhu\",\n",
        "    savedir=\"experiments/dmc_result\",\n",
        "    save_interval=1,\n",
        ")\n",
        "\n",
        "# Train DMC Agents\n",
        "trainer.start()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating log directory: experiments/dmc_result/doudizhu\n",
            "Saving arguments to experiments/dmc_result/doudizhu/meta.json\n",
            "Saving messages to experiments/dmc_result/doudizhu/out.log\n",
            "Saving logs data to experiments/dmc_result/doudizhu/logs.csv\n",
            "Saving logs' fields to experiments/dmc_result/doudizhu/fields.csv\n",
            "[INFO:60 trainer:335 2022-03-24 03:53:20,270] Saving checkpoint to experiments/dmc_result/doudizhu/model.tar\n",
            "[INFO:60 trainer:371 2022-03-24 03:53:20,701] After 0 frames: @ 0.0 fps Stats:\n",
            "{'loss_0': 0,\n",
            " 'loss_1': 0,\n",
            " 'loss_2': 0,\n",
            " 'mean_episode_return_0': 0,\n",
            " 'mean_episode_return_1': 0,\n",
            " 'mean_episode_return_2': 0}\n",
            "[INFO:60 trainer:371 2022-03-24 03:53:25,720] After 0 frames: @ 0.0 fps Stats:\n",
            "{'loss_0': 0,\n",
            " 'loss_1': 0,\n",
            " 'loss_2': 0,\n",
            " 'mean_episode_return_0': 0,\n",
            " 'mean_episode_return_1': 0,\n",
            " 'mean_episode_return_2': 0}\n",
            "[INFO:60 trainer:371 2022-03-24 03:53:30,754] After 0 frames: @ 0.0 fps Stats:\n",
            "{'loss_0': 0,\n",
            " 'loss_1': 0,\n",
            " 'loss_2': 0,\n",
            " 'mean_episode_return_0': 0,\n",
            " 'mean_episode_return_1': 0,\n",
            " 'mean_episode_return_2': 0}\n",
            "Updated log fields: ['_tick', '_time', 'frames', 'mean_episode_return_0', 'loss_0', 'mean_episode_return_1', 'loss_1', 'mean_episode_return_2', 'loss_2']\n",
            "[INFO:60 trainer:371 2022-03-24 03:53:35,768] After 3200 frames: @ 639.3 fps Stats:\n",
            "{'loss_0': 0.4258865416049957,\n",
            " 'loss_1': 0,\n",
            " 'loss_2': 0,\n",
            " 'mean_episode_return_0': 0.39743590354919434,\n",
            " 'mean_episode_return_1': 0,\n",
            " 'mean_episode_return_2': 0}\n",
            "[INFO:60 trainer:371 2022-03-24 03:53:40,775] After 9600 frames: @ 1278.9 fps Stats:\n",
            "{'loss_0': 0.4258865416049957,\n",
            " 'loss_1': 0.6387953758239746,\n",
            " 'loss_2': 0.6459171175956726,\n",
            " 'mean_episode_return_0': 0.39743590354919434,\n",
            " 'mean_episode_return_1': 0.597484290599823,\n",
            " 'mean_episode_return_2': 0.5987654328346252}\n",
            "[INFO:60 trainer:371 2022-03-24 03:53:45,785] After 9600 frames: @ 0.0 fps Stats:\n",
            "{'loss_0': 0.4258865416049957,\n",
            " 'loss_1': 0.6387953758239746,\n",
            " 'loss_2': 0.6459171175956726,\n",
            " 'mean_episode_return_0': 0.39743590354919434,\n",
            " 'mean_episode_return_1': 0.597484290599823,\n",
            " 'mean_episode_return_2': 0.5987654328346252}\n",
            "[INFO:60 trainer:371 2022-03-24 03:53:50,797] After 9600 frames: @ 0.0 fps Stats:\n",
            "{'loss_0': 0.4258865416049957,\n",
            " 'loss_1': 0.6387953758239746,\n",
            " 'loss_2': 0.6459171175956726,\n",
            " 'mean_episode_return_0': 0.39743590354919434,\n",
            " 'mean_episode_return_1': 0.597484290599823,\n",
            " 'mean_episode_return_2': 0.5987654328346252}\n",
            "[INFO:60 trainer:371 2022-03-24 03:53:55,809] After 19200 frames: @ 1918.3 fps Stats:\n",
            "{'loss_0': 0.3745853304862976,\n",
            " 'loss_1': 0.5792326927185059,\n",
            " 'loss_2': 0.5598975419998169,\n",
            " 'mean_episode_return_0': 0.4082987904548645,\n",
            " 'mean_episode_return_1': 0.5882158279418945,\n",
            " 'mean_episode_return_2': 0.589612603187561}\n",
            "[INFO:60 trainer:371 2022-03-24 03:54:00,821] After 19200 frames: @ 0.0 fps Stats:\n",
            "{'loss_0': 0.3745853304862976,\n",
            " 'loss_1': 0.5792326927185059,\n",
            " 'loss_2': 0.5598975419998169,\n",
            " 'mean_episode_return_0': 0.4082987904548645,\n",
            " 'mean_episode_return_1': 0.5882158279418945,\n",
            " 'mean_episode_return_2': 0.589612603187561}\n",
            "[INFO:60 trainer:371 2022-03-24 03:54:05,835] After 19200 frames: @ 0.0 fps Stats:\n",
            "{'loss_0': 0.3745853304862976,\n",
            " 'loss_1': 0.5792326927185059,\n",
            " 'loss_2': 0.5598975419998169,\n",
            " 'mean_episode_return_0': 0.4082987904548645,\n",
            " 'mean_episode_return_1': 0.5882158279418945,\n",
            " 'mean_episode_return_2': 0.589612603187561}\n",
            "[INFO:60 trainer:371 2022-03-24 03:54:10,847] After 19200 frames: @ 0.0 fps Stats:\n",
            "{'loss_0': 0.3745853304862976,\n",
            " 'loss_1': 0.5792326927185059,\n",
            " 'loss_2': 0.5598975419998169,\n",
            " 'mean_episode_return_0': 0.4082987904548645,\n",
            " 'mean_episode_return_1': 0.5882158279418945,\n",
            " 'mean_episode_return_2': 0.589612603187561}\n",
            "[INFO:60 trainer:371 2022-03-24 03:54:15,859] After 28800 frames: @ 1918.1 fps Stats:\n",
            "{'loss_0': 0.4179472327232361,\n",
            " 'loss_1': 0.4089127480983734,\n",
            " 'loss_2': 0.40309226512908936,\n",
            " 'mean_episode_return_0': 0.4541811943054199,\n",
            " 'mean_episode_return_1': 0.5466577410697937,\n",
            " 'mean_episode_return_2': 0.5452118515968323}\n",
            "[INFO:60 trainer:335 2022-03-24 03:54:20,868] Saving checkpoint to experiments/dmc_result/doudizhu/model.tar\n",
            "[INFO:60 trainer:371 2022-03-24 03:54:21,523] After 28800 frames: @ 0.0 fps Stats:\n",
            "{'loss_0': 0.4179472327232361,\n",
            " 'loss_1': 0.4089127480983734,\n",
            " 'loss_2': 0.40309226512908936,\n",
            " 'mean_episode_return_0': 0.4541811943054199,\n",
            " 'mean_episode_return_1': 0.5466577410697937,\n",
            " 'mean_episode_return_2': 0.5452118515968323}\n",
            "[INFO:60 trainer:371 2022-03-24 03:54:26,530] After 28800 frames: @ 0.0 fps Stats:\n",
            "{'loss_0': 0.4179472327232361,\n",
            " 'loss_1': 0.4089127480983734,\n",
            " 'loss_2': 0.40309226512908936,\n",
            " 'mean_episode_return_0': 0.4541811943054199,\n",
            " 'mean_episode_return_1': 0.5466577410697937,\n",
            " 'mean_episode_return_2': 0.5452118515968323}\n",
            "[INFO:60 trainer:371 2022-03-24 03:54:31,539] After 28800 frames: @ 0.0 fps Stats:\n",
            "{'loss_0': 0.4179472327232361,\n",
            " 'loss_1': 0.4089127480983734,\n",
            " 'loss_2': 0.40309226512908936,\n",
            " 'mean_episode_return_0': 0.4541811943054199,\n",
            " 'mean_episode_return_1': 0.5466577410697937,\n",
            " 'mean_episode_return_2': 0.5452118515968323}\n",
            "[INFO:60 trainer:371 2022-03-24 03:54:36,553] After 38400 frames: @ 1918.3 fps Stats:\n",
            "{'loss_0': 0.31496214866638184,\n",
            " 'loss_1': 0.3514341115951538,\n",
            " 'loss_2': 0.3326067328453064,\n",
            " 'mean_episode_return_0': 0.4701230823993683,\n",
            " 'mean_episode_return_1': 0.5306400656700134,\n",
            " 'mean_episode_return_2': 0.5302324295043945}\n"
          ]
        }
      ]
    }
  ]
}